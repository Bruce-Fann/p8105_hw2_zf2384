---
title: "p8105_hw2_zf2384"
author: "Zichen Fan"
date: "2025-10-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
```

## Problem 1
Clean pols-month
```{r clean_pols}
pols_df = read_csv("./data/pols-month.csv") |>
  # separate mon into year, month, day
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    # replace month number with month name
    month = month.name[month],
    # create president variable
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) |>
  # drop day, prez_gop, prez_dem
  select(-day, -prez_gop, -prez_dem)

head(pols_df)

```
 
Clean snp
```{r clean_snp}
snp_df = read_csv("./data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
    year = as.integer(year),
    # adjust year if given in 2-digit format
    year = ifelse(year > 50, 1900 + year, 2000 + year),
    month = as.integer(month),
    month = month.name[month]
  ) |>
  select(year, month, close) |>
  arrange(year, month)

head(snp_df)

```

clean unemploy
```{r clean_unemploy}
unemp_df = read_csv("./data/unemployment.csv") |>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemp_rate"
  ) |>
  mutate(
    month = match(month, month.abb),  # convert "Jan" → 1, etc
    month = month.name[month]
  ) |>
  rename(year = Year)
head(unemp_df)

```

Merge all data sets
```{r merge}
merged_df = pols_df |>
  left_join(snp_df, by = c("year", "month")) |>
  left_join(unemp_df, by = c("year", "month"))

merged_df

```

  The pols-month data set (822 observations, 1947–2015) records counts of governors,
senators, and representatives by party, plus the president’s party.The snp data set (787 observations, 1950s–2050) provides monthly closing values of the S&P stock index.

  The unemployment data set (816 observations, 1948–2015) contains monthly unemployment rates. After cleaning and merging, the combined data set has 822 monthly observations spanning 1947–2015, with key variables including party composition (gov_gop, sen_dem, rep_dem), president’s party, stock index values (close), and unemployment rates (unemp_rate).

## Problem 2

clean mr trash
```{r mr_trash}
library(readxl)

q2_path <- "data/202509 Trash Wheel Collection Data.xlsx"

sheet_mr_trash <- "Mr. Trash Wheel"

# Read the specified sheet, cleaning
mr_trash = read_excel(
  path = q2_path,
  sheet = sheet_mr_trash,)|>
  janitor::clean_names()|>
  select(dumpster:homes_powered)|>
   mutate(
    sports_balls = as.integer(round(sports_balls)))|>
      mutate(wheel_name = "mr_trash")|>
  mutate(year = as.numeric(year))
    
                    
```

clean professor trash and gwynnda

```{r professor_trash}
sheet_prof_trash <- "Professor Trash Wheel"

sheet_gwynns <- "Gwynns Falls Trash Wheel"

# Read the professor trash and gwynnda sheet, cleaning
prof_trash = read_excel(
  path = q2_path,
  sheet = sheet_prof_trash)|>
  janitor::clean_names() |>
   mutate(wheel_name = "prof_trash")

gwynns_trash = read_excel(
  path = q2_path,
  sheet = sheet_gwynns)|>
  janitor::clean_names() |>
   mutate(wheel_name = "gwynns_trash")

```

merge the sheets
```{r q2_merge}
all_trash_data = bind_rows(mr_trash , prof_trash , gwynns_trash) 

total_obs <- nrow(all_trash_data)

# calculate total weight of professor trash wheel
prof_total_weight = all_trash_data |>
  filter(wheel_name == "prof_trash") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight)

# total number of cigarette butts collected by Gwynnda in June of 2022
gwynnda_cigs_june22 = all_trash_data |>
  filter(
    wheel_name == "gwynns_trash",
    year == 2022,
    month == "June"
  ) |>
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE)) %>%
  pull(total_cigs)

```

  The combined data set contains observations from three different trash wheels in Baltimore, totaling 1191 collections. Key variables in this neat data set include wheel_name,which identifies the specific wheel, and a series of quantitative metrics such as weight_tons (tons of trash), plastic_bottles (number of plastic bottles), polystyrene (number of Styrofoam pieces), and cigarette_butts (number of cigarette butts). 

  Based on available data, the total weight of trash collected by the "Professor Trash Wheel" during its operation is approximately 564.52 tons. For a more specific question, the total number of cigarette butts collected by the Gwynns Falls trash wheel (Gwynnda) during June 2022 is 18120. 
  
## Problem 3

Import and wrangle
```{r q3_import}

zip_df = read_csv("./data/Zip Codes.csv") |>
  janitor::clean_names()  |>
  rename(borough = county)

zori_df = read_csv("./data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")|>
   janitor::clean_names()  |>
  
  ## make zip code column name consistent with zip_df
  rename(zip_code = region_name ) |>
  
  ## pivot the date information into rows because i prefer this
  pivot_longer(
    cols = matches("^x\\d{4}_\\d{2}_\\d{2}"), 
    names_to = "date",                   
    values_to = "zori"  ) |>
  ## edit the date format
 mutate(
   date = ymd(str_remove(date, "^x"))
       )
```

Merge zip code file with neighborhood and borough with ZORI file

```{r q3_merge}

final_df = zori_df |>
  left_join(zip_df, by = "zip_code")|>
  
  ## select key column for this problem and rearrange row order
select(date, city, borough, county_name, zip_code, neighborhood, zori) |>
  arrange(city, county_name, borough, zip_code,date)

```

Check observations
```{r q3_check}

n_obs = nrow(final_df)
n_zip = n_distinct(pull(final_df, zip_code))
n_neigh = n_distinct(pull(final_df, neighborhood))

n_obs
n_zip
n_neigh

```

The result data set only select date, city, borough, county name, zip code 
and ZORI as key information for analysis. It include 17516 observations of 
rent index in total, covering 43 neighborhood and 149 unique zip code.

```{r missing_zip}

## unique zip code
zillow_zips_vector = unique(pull(final_df, zip_code))

## see what's missing
missing_zips = zip_df |>
  filter(!zip_code %in% zillow_zips_vector)|>
  pull(zip_code)

print(missing_zips)
```

We are missing 171 zip code listed above in the final merged data frame.
This could be due to some ZIP codes appear in the ZIP dataset but not in Zillow rental data. 
These are often non-residential or sparsely populated areas (e.g., primarily commercial
or institutional areas like airports or campuses). 
Zillow does not provide rental indices for these places because there is little to no residential rental market.


```{r covid}
zori_change = final_df |>
  filter(month(date) %in% c(1), year(date) %in% c(2020, 2021)) |>
  mutate(year = year(date)) |>
  select(zip_code, borough, neighborhood, year, zori) |>
  pivot_wider(names_from = year, values_from = zori, names_prefix = "zori_") |>
  mutate(diff = zori_2021 - zori_2020) |>
  arrange(diff) |>
  slice(1:10)

print(zori_change)

```

These results show that the steepest rent declines between January 2020 
and January 2021 were concentrated in New york borough, or manhattan.
ssuch as Lower Manhattan, the Lower East Side, Chelsea, and Gramercy/Soho.
Drops of $700–900 per month reflect the sharp impact of the COVID-19 pandemic on demand in dense, high-rent areas, where many residents moved out or sought cheaper housing elsewhere.



